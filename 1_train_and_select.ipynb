{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deepflash_SC.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matjesg/bioimage_analysis/blob/master/1_train_and_select.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BZovilofhrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "LHGP8NywL-sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "cellView": "both",
        "outputId": "1bcbca1e-f1f8-457d-ae90-d3045449bdb9"
      },
      "source": [
        "#@title Set up Google Colab environment\n",
        "#@markdown Please run this cell to get started.\n",
        "%tensorflow_version 1.x\n",
        "#!pip install tensorflow-gpu==1.14\n",
        "!git clone https://github.com/matjesg/bioimage_analysis.git\n",
        "!pip install simpleITK\n",
        "%cd bioimage_analysis\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import keras.backend as K\n",
        "from unet import unet, preproc, lrfinder, utils\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'bioimage_analysis'...\n",
            "remote: Enumerating objects: 697, done.\u001b[K\n",
            "remote: Counting objects: 100% (697/697), done.\u001b[K\n",
            "remote: Compressing objects: 100% (657/657), done.\u001b[K\n",
            "remote: Total 697 (delta 52), reused 677 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (697/697), 41.99 MiB | 34.15 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Collecting simpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 75kB/s \n",
            "\u001b[?25hInstalling collected packages: simpleITK\n",
            "Successfully installed simpleITK-1.2.4\n",
            "/content/bioimage_analysis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "dnBXTRubeh7g"
      },
      "source": [
        "# Traing and model selection pipeline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "text",
        "id": "nQ09MgFGeh7u"
      },
      "source": [
        "## Set parameters \n",
        "__Laboratory, consensus strategy, and model weights__\n",
        "- `LAB`: one of `inns1`, `inns2`, `mue`, `wue1`, `wue2`\n",
        "- `STRATEGY`: `consensus` or expert_x (e.g., `expert_1`) models\n",
        "- `PRETRAINED_WEIGHTS`: weights for model initialization (`None` for random initialization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Vyt1jH3iL-sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAB = 'wue2'\n",
        "STRATEGY = 'consensus'\n",
        "PRETRAINED_WEIGHTS = None\n",
        "\n",
        "# Other parameters as used in our paper\n",
        "BATCH_SIZE = 4\n",
        "TILE_SHAPE = (540,540)\n",
        "PADDING = (184,184)\n",
        "\n",
        "# Loss weights calculation\n",
        "LAMBDA = 50 \n",
        "V_BAL = 0.1 \n",
        "SIGMA_BAL = 10 \n",
        "SIGMA_SEP = 6"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "lDWXMLbyL-sr",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab_type": "code",
        "id": "MP_sx-K5eh79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "171e80ee-8888-4701-e660-437a275314ed"
      },
      "source": [
        "DATA_PATH = \"train_data/lab-{}/images/\".format(LAB)\n",
        "MASK_PATH = \"train_data/lab-{}/labels/\".format(LAB)\n",
        "EXPERTS = [x for x in os.listdir(MASK_PATH) if x.startswith('expert')]\n",
        "LABEL_TYPE = os.listdir(os.path.join(MASK_PATH,EXPERTS[0]))[0].split('_')[1][:-4]\n",
        "\n",
        "# Get IDs\n",
        "file_ids = [x.rsplit('.',1)[0] for x in os.listdir(DATA_PATH)]\n",
        "\n",
        "# Load images\n",
        "images = [np.expand_dims(io.imread(os.path.join(DATA_PATH, x), as_gray=True), axis=2)\n",
        "          for x in [s + '.png' for s in file_ids]]\n",
        "\n",
        "# Load expert segmentation masks\n",
        "mask_dict = {}\n",
        "for exp in EXPERTS:\n",
        "    mask_dict[exp] = [io.imread(os.path.join(MASK_PATH, exp, x), as_gray=True).astype('int')//255 \n",
        "                      for x in [s + '_' + LABEL_TYPE + '.png' for s in file_ids]]\n",
        "\n",
        "# Load consensus (STAPLE)\n",
        "mask_dict['consensus'] = [io.imread(os.path.join(MASK_PATH, 'est_GT', x), as_gray=True).astype('int')//255 \n",
        "                          for x in [s + '_' + LABEL_TYPE + '.png' for s in file_ids]]\n",
        "\n",
        "## (Re-)compute consensus with simple ITK, if necassary\n",
        "# mask_dict['consensus'] = [utils.staple([mask_dict[exp][i] for exp in EXPERTS]) for i in range(len(file_ids))]\n",
        "\n",
        "# Create generator\n",
        "data = [{'rawdata': img, 'element_size_um': [1, 1]} for img in np.array(images)]\n",
        "gen = preproc.DataAugmentationGenerator(data = data, \n",
        "                                        classlabels=np.array(mask_dict[STRATEGY]),\n",
        "                                        tile_shape = TILE_SHAPE, \n",
        "                                        padding= PADDING,\n",
        "                                        batch_size = 2, # only for learning rate finder\n",
        "                                        n_classes=2,\n",
        "                                        rotation_range_deg=(0, 360),\n",
        "                                        flip=False,\n",
        "                                        deformation_grid=(150, 150),\n",
        "                                        deformation_magnitude=(10, 10),\n",
        "                                        value_minimum_range=(0, 0),\n",
        "                                        value_maximum_range=(0.0, 1),\n",
        "                                        value_slope_range=(1, 1),\n",
        "                                        shuffle=True,\n",
        "                                        foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                        border_weight_sigma_px=SIGMA_SEP,\n",
        "                                        border_weight_factor=LAMBDA,\n",
        "                                        foreground_background_ratio=V_BAL\n",
        "                                        )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:20<00:00,  4.20s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "HbAY0CmoL-sw",
        "colab_type": "text"
      },
      "source": [
        "## Training procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "q3fUoNyVL-sx",
        "colab_type": "text"
      },
      "source": [
        "1. Splitting the data into train and validation set (random stratified sampling)\n",
        "1. Determining the learning rate using the learning rate finder (Smith, 2018)\n",
        "1. Training the model with cyclical learning rates according to the fit-one-cycle policy of Smith (2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "bo6BUsMHL-sx",
        "colab_type": "text"
      },
      "source": [
        "### Learning Rate Finder\n",
        "Examplary use, results may vary (see  Smith, (2018))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "KHmZO2wxL-sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "b8588fce-b7d2-4450-ae10-3ef1d219e70e"
      },
      "source": [
        "# Create model\n",
        "model = unet.Unet2D(snapshot=PRETRAINED_WEIGHTS)\n",
        "\n",
        "# Create and run Learning Rate Finder\n",
        "lrfind = lrfinder.LRFinder(model.trainModel)\n",
        "lrfind.find(gen, start_lr=1e-7, lr_mult=1.1, verbose=0)\n",
        "\n",
        "# Plot loss\n",
        "lrfind.plot_loss()\n",
        "\n",
        "# Free GPU Memory\n",
        "sess = K.get_session()\n",
        "K.clear_session()\n",
        "sess.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "-YGTTxj_L-s2",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "We used \n",
        "- `SEED` to shuffle train-/validation data (defines the ensemble number, e.g. wue1_ __consensus2__ _model1 for `SEED=2`)) \n",
        "- stratified k-fold cross-validation (the fold later defines the model number, e.g. wue1_consensus2_ __model1__)\n",
        "- `max_lr = 5e-4` for _lab-wue1_ and `max_lr = 1e-4` for all other labs as maximum learning rate, according to the learning rate finder\n",
        "- a cycle length of 972 iterations (27 epochs)\n",
        "    - For faster computation, we randomly sampled 9 (_lab-wue1_) or 36 (other labs) tiles from each augmented image in each epoch\n",
        "\n",
        "We predicted validation images from the saved model weights after each epoch for the post-hoc evaluation. Validation during training was based on image tiles only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "8gnp7u6zL-s3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "242f72dd-a653-4eb2-fdfa-3f4155442988"
      },
      "source": [
        "SEED = 1\n",
        "skf = StratifiedKFold(n_splits= 4 if LAB == 'wue1' else 5, \n",
        "                      random_state=SEED, shuffle=True)\n",
        "\n",
        "# Define properties for stratified sampling\n",
        "if LAB == 'wue1': \n",
        "    strata = pd.read_csv('train_data/lab-wue1/groups_wue1.csv', dtype='str')\n",
        "else: \n",
        "    strata = pd.DataFrame({'file_id': file_ids, 'group_id':0})\n",
        "\n",
        "pred_dict = {}\n",
        "fold = 0\n",
        "for train_index, val_index in skf.split(strata['file_id'], strata['group_id']):\n",
        "    fold += 1\n",
        "    name = LAB + '_' + STRATEGY + str(SEED) + '_' + str(fold) \n",
        "    print(name)\n",
        "    \n",
        "    # Split training and validation data\n",
        "    X_train_cv, X_val_cv = np.array(images)[train_index], np.array(images)[val_index]\n",
        "    masks = mask_dict[STRATEGY]\n",
        "    y_train_cv, y_val_cv = np.array(masks)[train_index], np.array(masks)[val_index]\n",
        "    W_train_cv = np.array(gen.weights)[train_index]\n",
        "    data_train_cv = [{'rawdata': img, 'element_size_um': [1, 1]} for img in X_train_cv]\n",
        "    data_val_cv = [{'rawdata': img, 'element_size_um': [1, 1]} for img in X_val_cv]\n",
        "\n",
        "    # Create train generator\n",
        "    train_generator = preproc.DataAugmentationGenerator(data = data_train_cv, \n",
        "                                                classlabels=y_train_cv,\n",
        "                                                instancelabels=None,\n",
        "                                                tile_shape = TILE_SHAPE, \n",
        "                                                padding= PADDING,\n",
        "                                                batch_size = 4,\n",
        "                                                n_classes=2,\n",
        "                                                ignore=None,\n",
        "                                                weights=list(W_train_cv),\n",
        "                                                element_size_um=None,\n",
        "                                                rotation_range_deg=(0, 360),\n",
        "                                                flip=False,\n",
        "                                                deformation_grid=(150, 150),\n",
        "                                                deformation_magnitude=(10, 10),\n",
        "                                                value_minimum_range=(0, 0),\n",
        "                                                value_maximum_range=(0.0, 1),\n",
        "                                                value_slope_range=(1, 1),\n",
        "                                                shuffle=True,\n",
        "                                                foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                                border_weight_sigma_px=SIGMA_SEP,\n",
        "                                                border_weight_factor=LAMBDA,\n",
        "                                                foreground_background_ratio=V_BAL)\n",
        "    # Create validation generator\n",
        "    tile_generator_val = preproc.TileGenerator(data_val_cv, TILE_SHAPE, PADDING, \n",
        "                                           classlabels=y_val_cv,\n",
        "                                           foreground_dist_sigma_px=SIGMA_BAL,\n",
        "                                           border_weight_sigma_px=SIGMA_SEP,\n",
        "                                           border_weight_factor=LAMBDA,\n",
        "                                           foreground_background_ratio=V_BAL)\n",
        "    \n",
        "    # Create model\n",
        "    model = unet.Unet2D(snapshot=PRETRAINED_WEIGHTS, name=name)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit_one_cycle(train_generator, \n",
        "                        max_lr = 5e-4 if LAB == 'wue1' else 1e-4,\n",
        "                        final_epoch = 12 if LAB == 'wue1' else 27,\n",
        "                        validation_generator= tile_generator_val, \n",
        "                        snapshot_dir = '_cp/fold'+str(fold),\n",
        "                        snapshot_prefix=name,\n",
        "                        step_muliplier=9 if LAB == 'wue1' else 36)\n",
        "\n",
        "    # Free GPU Memory\n",
        "    sess = K.get_session()\n",
        "    K.clear_session()\n",
        "    sess.close()\n",
        "\n",
        "    # Get checkpoint names\n",
        "    cps = sorted([x for x in os.listdir('_cp/fold'+str(fold)) if x.startswith(name)])\n",
        "    file_ids_val = list(np.array(file_ids)[val_index])\n",
        "\n",
        "    # Predict validation images for post-hoc evaluation\n",
        "    for cp in sorted(cps):\n",
        "        print(cp)\n",
        "        pred_model = unet.Unet2D(snapshot=os.path.join('_cp/fold'+str(fold), cp))\n",
        "        predictions = pred_model.predict(tile_generator_val)   \n",
        "        for i, idx in enumerate(file_ids_val):           \n",
        "            pred_dict[(cp, idx)] = predictions[1][i]\n",
        "        \n",
        "        # Free GPU Memory\n",
        "        sess = K.get_session()\n",
        "        K.clear_session()\n",
        "        sess.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 56.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_1\n",
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  callbacks=callbacks)\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<unet.prep..., steps_per_epoch=36.0, epochs=2, initial_epoch=0, validation_data=<unet.prep..., verbose=True, callbacks=[<keras.ca..., validation_steps=9)`\n",
            "  callbacks=callbacks)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "36/36 [==============================] - 110s 3s/step - loss: 0.3170 - val_loss: 0.5203\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 86s 2s/step - loss: 0.1649 - val_loss: 0.2238\n",
            "wue2_consensus1_1.0001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "100%|██████████| 9/9 [00:02<00:00,  3.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_1.0002.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.34it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 57.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_2\n",
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  callbacks=callbacks)\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<unet.prep..., steps_per_epoch=36.0, epochs=2, initial_epoch=0, validation_data=<unet.prep..., verbose=True, callbacks=[<keras.ca..., validation_steps=9)`\n",
            "  callbacks=callbacks)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "36/36 [==============================] - 90s 3s/step - loss: 0.5217 - val_loss: 0.5151\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 86s 2s/step - loss: 0.1881 - val_loss: 0.1837\n",
            "wue2_consensus1_2.0001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "100%|██████████| 9/9 [00:02<00:00,  3.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_2.0002.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.34it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 49.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_3\n",
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  callbacks=callbacks)\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<unet.prep..., steps_per_epoch=36.0, epochs=2, initial_epoch=0, validation_data=<unet.prep..., verbose=True, callbacks=[<keras.ca..., validation_steps=9)`\n",
            "  callbacks=callbacks)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "36/36 [==============================] - 90s 3s/step - loss: 0.4830 - val_loss: 0.4454\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 86s 2s/step - loss: 0.1725 - val_loss: 0.1625\n",
            "wue2_consensus1_3.0001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "100%|██████████| 9/9 [00:02<00:00,  3.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_3.0002.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.34it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 51.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_4\n",
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:09<00:00,  9.57s/it]\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  callbacks=callbacks)\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<unet.prep..., steps_per_epoch=36.0, epochs=2, initial_epoch=0, validation_data=<unet.prep..., verbose=True, callbacks=[<keras.ca..., validation_steps=9)`\n",
            "  callbacks=callbacks)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "36/36 [==============================] - 90s 3s/step - loss: 0.5029 - val_loss: 0.4711\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 85s 2s/step - loss: 0.1755 - val_loss: 0.2780\n",
            "wue2_consensus1_4.0001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "100%|██████████| 9/9 [00:02<00:00,  3.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_4.0002.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.36it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 50.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_5\n",
            "Processing training samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  callbacks=callbacks)\n",
            "/content/bioimage_analysis/unet/unet.py:226: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<unet.prep..., steps_per_epoch=36.0, epochs=2, initial_epoch=0, validation_data=<unet.prep..., verbose=True, callbacks=[<keras.ca..., validation_steps=9)`\n",
            "  callbacks=callbacks)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "36/36 [==============================] - 90s 2s/step - loss: 0.4393 - val_loss: 0.4422\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 85s 2s/step - loss: 0.1918 - val_loss: 0.1149\n",
            "wue2_consensus1_5.0001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to softmax_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n",
            "100%|██████████| 9/9 [00:02<00:00,  3.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wue2_consensus1_5.0002.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "xallCZxjL-s7",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "2mipZoCbL-s8",
        "colab_type": "text"
      },
      "source": [
        "Selecting the model with the highest F1 score on the validation set. We used\n",
        "- `MIN_PIXEL` to approximate the minimum biologically justifiable size based on the smallest area that was annotated by a human expert \n",
        "- `IOU_t=0.5` as IoU threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "80er644PL-s9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_PIXEL = {'inns1':16, 'inns2':60, 'mue':30, 'wue1':30, 'wue2':112}\n",
        "IOU_t=0.5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "jVpo2oXtL-tC",
        "colab_type": "text"
      },
      "source": [
        "__Similarity analysis and model selection__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "SFH8gkL8L-tC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "cd1ed566-ada3-4d76-ce85-65dcb55c87ac"
      },
      "source": [
        "res_list = []\n",
        "for i, idx in enumerate(file_ids):\n",
        "    # Exclude area from analysis (wue2 only)\n",
        "    if LAB == 'wue2':\n",
        "        exclude = [io.imread(os.path.join(\"train_data/lab-wue2/ignored_regions/\", x), as_gray=True)//255 for \n",
        "                   x in [idx + '_ignore.png' for s in file_ids]]\n",
        "        for exp in EXPERTS+['consensus']:\n",
        "            mask_dict[exp][i][exclude[i]==1]=0\n",
        "        for cp, idx2 in pred_dict:\n",
        "            if idx==idx2:\n",
        "                pred_dict[(cp, idx)][exclude[i]==1]=0\n",
        "\n",
        "    # Label connected regions\n",
        "    label_a = utils.label_mask(mask_dict['consensus'][i], min_pixel=MIN_PIXEL[LAB])\n",
        "    for exp in EXPERTS:\n",
        "        # Label connected regions\n",
        "        label_b =  utils.label_mask(mask_dict[exp][i], min_pixel=MIN_PIXEL[LAB])\n",
        "        # Match ROIs\n",
        "        tmp_res =  utils.iou_mapping(label_a, label_b, min_roi_size=MIN_PIXEL[LAB])\n",
        "        df_exp = pd.Series({'FileId' : idx,\n",
        "                            'Type': 'ref',\n",
        "                              'cp_name' : exp,\n",
        "                              'count_a': tmp_res[3], \n",
        "                              'count_b': tmp_res[4], \n",
        "                              'matches_iou' : tmp_res[0]})\n",
        "        res_list += [df_exp]\n",
        "    for cp, idx2 in pred_dict:\n",
        "        if idx==idx2:\n",
        "            # Label connected regions\n",
        "            label_b =  utils.label_mask(pred_dict[(cp, idx)], min_pixel=MIN_PIXEL[LAB])\n",
        "            # Match ROIs\n",
        "            tmp_res =  utils.iou_mapping(label_a, label_b, min_roi_size=MIN_PIXEL[LAB])\n",
        "            df_pred = pd.Series({'FileId' : idx,\n",
        "                                'Type': 'pred',\n",
        "                                  'cp_name' : cp,\n",
        "                                  'count_a': tmp_res[3], \n",
        "                                  'count_b': tmp_res[4], \n",
        "                                  'matches_iou' : tmp_res[0]})\n",
        "            res_list += [df_pred]\n",
        "            \n",
        "# Compute precision, recall, and F1 score\n",
        "df = pd.DataFrame(res_list)\n",
        "df['fold'] = df['cp_name'].str[-9:-8]\n",
        "df['matches'] =  df['matches_iou'].apply(lambda x : x[x>IOU_t].shape[0] if len(x)>0 else 0)\n",
        "df['precision'] =  df.matches/df.count_a\n",
        "df['recall'] = df.matches/df.count_b\n",
        "df['f1_score'] = 2 * (df.precision * df.recall) / (df.precision + df.recall)\n",
        "\n",
        "# # filter models below expert reference lower bound\n",
        "exp_lb = df[df.Type=='ref'].groupby('FileId').f1_score.min()\n",
        "exp_lb.name = 'f1_lb'\n",
        "df_pred = df[df.Type=='pred'].join(exp_lb, on='FileId')\n",
        "#df_pred = df_pred[df_pred.f1_lb<df_pred.f1_score]\n",
        "\n",
        "# select models with highest f1 score (f1 score median)\n",
        "df_select = (df_pred.groupby(['fold', 'cp_name'])\n",
        "             .f1_score.agg(['median', 'count'])\n",
        "             .reset_index('cp_name')\n",
        "             .sort_values('median')\n",
        "             .groupby(['fold'])\n",
        "             .first().reset_index())\n",
        "df_select = df_select[df_select['count']==len(val_index)]\n",
        "df_select['ensemble_model_number'] = df_select.cp_name.str[:-9]+'model'+df_select.fold\n",
        "\n",
        "# Print models selected for ensembling\n",
        "df_select[['cp_name', 'ensemble_model_number']]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_name</th>\n",
              "      <th>ensemble_model_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wue2_consensus1_1.0001.h5</td>\n",
              "      <td>wue2_consensus1_model1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wue2_consensus1_4.0002.h5</td>\n",
              "      <td>wue2_consensus1_model4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wue2_consensus1_5.0002.h5</td>\n",
              "      <td>wue2_consensus1_model5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     cp_name   ensemble_model_number\n",
              "0  wue2_consensus1_1.0001.h5  wue2_consensus1_model1\n",
              "3  wue2_consensus1_4.0002.h5  wue2_consensus1_model4\n",
              "4  wue2_consensus1_5.0002.h5  wue2_consensus1_model5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}